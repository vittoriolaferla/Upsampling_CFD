{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed: 255_suffix.png -> 255.png\n",
      "Renamed: 601_suffix.png -> 601.png\n",
      "Renamed: 488_suffix.png -> 488.png\n",
      "Renamed: 541_suffix.png -> 541.png\n",
      "Renamed: 17_suffix.png -> 17.png\n",
      "Renamed: 237_suffix.png -> 237.png\n",
      "Renamed: 102_suffix.png -> 102.png\n",
      "Renamed: 967_suffix.png -> 967.png\n",
      "Renamed: 877_suffix.png -> 877.png\n",
      "Renamed: 547_suffix.png -> 547.png\n",
      "Renamed: 688_suffix.png -> 688.png\n",
      "Renamed: 484_suffix.png -> 484.png\n",
      "Renamed: 401_suffix.png -> 401.png\n",
      "Renamed: 375_suffix.png -> 375.png\n",
      "Renamed: 482_suffix.png -> 482.png\n",
      "Renamed: 487_suffix.png -> 487.png\n",
      "Renamed: 241_suffix.png -> 241.png\n",
      "Renamed: 627_suffix.png -> 627.png\n",
      "Renamed: 367_suffix.png -> 367.png\n",
      "Renamed: 517_suffix.png -> 517.png\n",
      "Renamed: 500_suffix.png -> 500.png\n",
      "Renamed: 802_suffix.png -> 802.png\n",
      "Renamed: 84_suffix.png -> 84.png\n",
      "Renamed: 598_suffix.png -> 598.png\n",
      "Renamed: 192_suffix.png -> 192.png\n",
      "Renamed: 125_suffix.png -> 125.png\n",
      "Renamed: 754_suffix.png -> 754.png\n",
      "Renamed: 121_suffix.png -> 121.png\n",
      "Renamed: 611_suffix.png -> 611.png\n",
      "Renamed: 214_suffix.png -> 214.png\n",
      "Renamed: 821_suffix.png -> 821.png\n",
      "Renamed: 831_suffix.png -> 831.png\n",
      "Renamed: 972_suffix.png -> 972.png\n",
      "Renamed: 909_suffix.png -> 909.png\n",
      "Renamed: 476_suffix.png -> 476.png\n",
      "Renamed: 338_suffix.png -> 338.png\n",
      "Renamed: 371_suffix.png -> 371.png\n",
      "Renamed: 443_suffix.png -> 443.png\n",
      "Renamed: 319_suffix.png -> 319.png\n",
      "Renamed: 910_suffix.png -> 910.png\n",
      "Renamed: 945_suffix.png -> 945.png\n",
      "Renamed: 573_suffix.png -> 573.png\n",
      "Renamed: 954_suffix.png -> 954.png\n",
      "Renamed: 174_suffix.png -> 174.png\n",
      "Renamed: 712_suffix.png -> 712.png\n",
      "Renamed: 433_suffix.png -> 433.png\n",
      "Renamed: 759_suffix.png -> 759.png\n",
      "Renamed: 897_suffix.png -> 897.png\n",
      "Renamed: 766_suffix.png -> 766.png\n",
      "Renamed: 352_suffix.png -> 352.png\n",
      "Renamed: 413_suffix.png -> 413.png\n",
      "Renamed: 713_suffix.png -> 713.png\n",
      "Renamed: 612_suffix.png -> 612.png\n",
      "Renamed: 374_suffix.png -> 374.png\n",
      "Renamed: 944_suffix.png -> 944.png\n",
      "Renamed: 603_suffix.png -> 603.png\n",
      "Renamed: 226_suffix.png -> 226.png\n",
      "Renamed: 49_suffix.png -> 49.png\n",
      "Renamed: 201_suffix.png -> 201.png\n",
      "Renamed: 221_suffix.png -> 221.png\n",
      "Renamed: 138_suffix.png -> 138.png\n",
      "Renamed: 32_suffix.png -> 32.png\n",
      "Renamed: 361_suffix.png -> 361.png\n",
      "Renamed: 87_suffix.png -> 87.png\n",
      "Renamed: 8_suffix.png -> 8.png\n",
      "Renamed: 148_suffix.png -> 148.png\n",
      "Renamed: 690_suffix.png -> 690.png\n",
      "Renamed: 729_suffix.png -> 729.png\n",
      "Renamed: 578_suffix.png -> 578.png\n",
      "Renamed: 185_suffix.png -> 185.png\n",
      "Renamed: 120_suffix.png -> 120.png\n",
      "Renamed: 283_suffix.png -> 283.png\n",
      "Renamed: 74_suffix.png -> 74.png\n",
      "Renamed: 691_suffix.png -> 691.png\n",
      "Renamed: 357_suffix.png -> 357.png\n",
      "Renamed: 190_suffix.png -> 190.png\n",
      "Renamed: 314_suffix.png -> 314.png\n",
      "Renamed: 932_suffix.png -> 932.png\n",
      "Renamed: 723_suffix.png -> 723.png\n",
      "Renamed: 656_suffix.png -> 656.png\n",
      "Renamed: 458_suffix.png -> 458.png\n",
      "Renamed: 765_suffix.png -> 765.png\n",
      "Renamed: 874_suffix.png -> 874.png\n",
      "Renamed: 770_suffix.png -> 770.png\n",
      "Renamed: 812_suffix.png -> 812.png\n",
      "Renamed: 958_suffix.png -> 958.png\n",
      "Renamed: 54_suffix.png -> 54.png\n",
      "Renamed: 969_suffix.png -> 969.png\n",
      "Renamed: 454_suffix.png -> 454.png\n",
      "Renamed: 622_suffix.png -> 622.png\n",
      "Renamed: 231_suffix.png -> 231.png\n",
      "Renamed: 464_suffix.png -> 464.png\n",
      "Renamed: 979_suffix.png -> 979.png\n",
      "Renamed: 31_suffix.png -> 31.png\n",
      "Renamed: 316_suffix.png -> 316.png\n",
      "Renamed: 532_suffix.png -> 532.png\n",
      "Renamed: 220_suffix.png -> 220.png\n",
      "Renamed: 126_suffix.png -> 126.png\n",
      "Renamed: 489_suffix.png -> 489.png\n",
      "Renamed: 48_suffix.png -> 48.png\n",
      "Renamed: 745_suffix.png -> 745.png\n",
      "Renamed: 339_suffix.png -> 339.png\n",
      "Renamed: 423_suffix.png -> 423.png\n",
      "Renamed: 497_suffix.png -> 497.png\n",
      "Renamed: 888_suffix.png -> 888.png\n",
      "Renamed: 618_suffix.png -> 618.png\n",
      "Renamed: 335_suffix.png -> 335.png\n",
      "Renamed: 565_suffix.png -> 565.png\n",
      "Renamed: 83_suffix.png -> 83.png\n",
      "Renamed: 512_suffix.png -> 512.png\n",
      "Renamed: 219_suffix.png -> 219.png\n",
      "Renamed: 346_suffix.png -> 346.png\n",
      "Renamed: 976_suffix.png -> 976.png\n",
      "Renamed: 753_suffix.png -> 753.png\n",
      "Renamed: 999_suffix.png -> 999.png\n",
      "Renamed: 511_suffix.png -> 511.png\n",
      "Renamed: 453_suffix.png -> 453.png\n",
      "Renamed: 662_suffix.png -> 662.png\n",
      "Renamed: 647_suffix.png -> 647.png\n",
      "Renamed: 988_suffix.png -> 988.png\n",
      "Renamed: 7_suffix.png -> 7.png\n",
      "Renamed: 982_suffix.png -> 982.png\n",
      "Renamed: 232_suffix.png -> 232.png\n",
      "Renamed: 123_suffix.png -> 123.png\n",
      "Renamed: 589_suffix.png -> 589.png\n",
      "Renamed: 16_suffix.png -> 16.png\n",
      "Renamed: 626_suffix.png -> 626.png\n",
      "Renamed: 301_suffix.png -> 301.png\n",
      "Renamed: 728_suffix.png -> 728.png\n",
      "Renamed: 247_suffix.png -> 247.png\n",
      "Renamed: 832_suffix.png -> 832.png\n",
      "Renamed: 795_suffix.png -> 795.png\n",
      "Renamed: 540_suffix.png -> 540.png\n",
      "Renamed: 774_suffix.png -> 774.png\n",
      "Renamed: 816_suffix.png -> 816.png\n",
      "Renamed: 859_suffix.png -> 859.png\n",
      "Renamed: 771_suffix.png -> 771.png\n",
      "Renamed: 582_suffix.png -> 582.png\n",
      "Renamed: 635_suffix.png -> 635.png\n",
      "Renamed: 257_suffix.png -> 257.png\n",
      "Renamed: 40_suffix.png -> 40.png\n",
      "Renamed: 298_suffix.png -> 298.png\n",
      "Renamed: 145_suffix.png -> 145.png\n",
      "Renamed: 750_suffix.png -> 750.png\n",
      "Renamed: 14_suffix.png -> 14.png\n",
      "Renamed: 858_suffix.png -> 858.png\n",
      "Renamed: 1_suffix.png -> 1.png\n",
      "Renamed: 900_suffix.png -> 900.png\n",
      "Renamed: 389_suffix.png -> 389.png\n",
      "Renamed: 568_suffix.png -> 568.png\n",
      "Renamed: 783_suffix.png -> 783.png\n",
      "Renamed: 364_suffix.png -> 364.png\n",
      "Renamed: 101_suffix.png -> 101.png\n",
      "Renamed: 847_suffix.png -> 847.png\n",
      "Renamed: 791_suffix.png -> 791.png\n",
      "Renamed: 88_suffix.png -> 88.png\n",
      "Renamed: 469_suffix.png -> 469.png\n",
      "Renamed: 850_suffix.png -> 850.png\n",
      "Renamed: 814_suffix.png -> 814.png\n",
      "Renamed: 398_suffix.png -> 398.png\n",
      "Renamed: 555_suffix.png -> 555.png\n",
      "Renamed: 593_suffix.png -> 593.png\n",
      "Renamed: 590_suffix.png -> 590.png\n",
      "Renamed: 760_suffix.png -> 760.png\n",
      "Renamed: 714_suffix.png -> 714.png\n",
      "Renamed: 233_suffix.png -> 233.png\n",
      "Renamed: 619_suffix.png -> 619.png\n",
      "Renamed: 856_suffix.png -> 856.png\n",
      "Renamed: 27_suffix.png -> 27.png\n",
      "Renamed: 663_suffix.png -> 663.png\n",
      "Renamed: 432_suffix.png -> 432.png\n",
      "Renamed: 406_suffix.png -> 406.png\n",
      "Renamed: 809_suffix.png -> 809.png\n",
      "Renamed: 732_suffix.png -> 732.png\n",
      "Renamed: 156_suffix.png -> 156.png\n",
      "Renamed: 768_suffix.png -> 768.png\n",
      "Renamed: 629_suffix.png -> 629.png\n",
      "Renamed: 631_suffix.png -> 631.png\n",
      "Renamed: 384_suffix.png -> 384.png\n",
      "Renamed: 393_suffix.png -> 393.png\n",
      "Renamed: 439_suffix.png -> 439.png\n",
      "Renamed: 644_suffix.png -> 644.png\n",
      "Renamed: 425_suffix.png -> 425.png\n",
      "Renamed: 181_suffix.png -> 181.png\n",
      "Renamed: 290_suffix.png -> 290.png\n",
      "Renamed: 828_suffix.png -> 828.png\n",
      "Renamed: 650_suffix.png -> 650.png\n",
      "Renamed: 127_suffix.png -> 127.png\n",
      "Renamed: 871_suffix.png -> 871.png\n",
      "Renamed: 341_suffix.png -> 341.png\n",
      "Renamed: 885_suffix.png -> 885.png\n",
      "Renamed: 303_suffix.png -> 303.png\n",
      "Renamed: 78_suffix.png -> 78.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the directory containing the images\n",
    "image_folder = \"/home/vittorio/Documenti/Upsampling_CFD/results/test_DAT_x2_outdoor_no_umass/visualization/test_set_physic\"\n",
    "# The suffix you want to remove\n",
    "suffix_to_remove = \"_suffix\"\n",
    "\n",
    "# Get all files in the directory\n",
    "for filename in os.listdir(image_folder):\n",
    "    # Check if it's a file (not a directory) and if it ends with the suffix you want to remove\n",
    "    if os.path.isfile(os.path.join(image_folder, filename)):\n",
    "        # Split the filename into name and extension\n",
    "        file_name, file_ext = os.path.splitext(filename)\n",
    "        \n",
    "        # If the file ends with the suffix, rename it\n",
    "        if file_name.endswith(suffix_to_remove):\n",
    "            new_name = file_name[:-len(suffix_to_remove)] + file_ext\n",
    "            # Rename the file\n",
    "            os.rename(os.path.join(image_folder, filename), os.path.join(image_folder, new_name))\n",
    "            print(f\"Renamed: {filename} -> {new_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vittorio/anaconda3/envs/Upsampling/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Calculating PSNR:   0%|          | 0/193 [00:00<?, ?it/s]<ipython-input-2-7e0226174202>:20: UserWarning: Using a target size (torch.Size([3, 256, 256])) that is different to the input size (torch.Size([3, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  mse = F.mse_loss(pred, target)\n",
      "Calculating PSNR:   0%|          | 0/193 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (256) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7e0226174202>\u001b[0m in \u001b[0;36m<cell line: 97>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m# Calculate PSNR for the model's output (ResShift)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m avg_psnr_resShift = calculate_psnr_from_folders(\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mpred_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_folder_resShift\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mtarget_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_folder_resShift\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7e0226174202>\u001b[0m in \u001b[0;36mcalculate_psnr_from_folders\u001b[0;34m(pred_folder, target_folder, upscale_factor, device)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Compute PSNR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mpsnr_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mtotal_psnr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpsnr_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mtotal_images\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7e0226174202>\u001b[0m in \u001b[0;36mpsnr\u001b[0;34m(pred, target, max_val)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPSNR\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecibels\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Perfect match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Upsampling/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2923\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2925\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2926\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Upsampling/lib/python3.8/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (256) at non-singleton dimension 2"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm  # Ensure tqdm is imported for progress bar\n",
    "\n",
    "def psnr(pred, target, max_val=1.0):\n",
    "    \"\"\"\n",
    "    Compute the Peak Signal-to-Noise Ratio (PSNR) between two images.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): Predicted image tensor of shape [C, H, W].\n",
    "        target (torch.Tensor): Target image tensor of shape [C, H, W].\n",
    "        max_val (float, optional): Maximum possible pixel value. Defaults to 1.0.\n",
    "\n",
    "    Returns:\n",
    "        float: PSNR value in decibels (dB).\n",
    "    \"\"\"\n",
    "    mse = F.mse_loss(pred, target)\n",
    "    if mse == 0:\n",
    "        return float('inf')  # Perfect match\n",
    "    psnr_value = 20 * torch.log10(max_val / torch.sqrt(mse))\n",
    "    return psnr_value.item()\n",
    "\n",
    "def calculate_psnr_from_folders(pred_folder, target_folder, upscale_factor=1, device='cpu'):\n",
    "    \"\"\"\n",
    "    Calculate the average PSNR between images in two folders.\n",
    "\n",
    "    Args:\n",
    "        pred_folder (str): Path to the folder containing predicted/downsampled images.\n",
    "        target_folder (str): Path to the folder containing target high-resolution images.\n",
    "        upscale_factor (int, optional): Factor by which to upscale the predicted images.\n",
    "                                        Defaults to 1 (no upscaling).\n",
    "        device (torch.device, optional): Device to perform computations on. Defaults to 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        float: Average PSNR value.\n",
    "    \"\"\"\n",
    "    total_psnr = 0.0\n",
    "    total_images = 0\n",
    "\n",
    "    # Get sorted lists of image filenames\n",
    "    pred_images = sorted(os.listdir(pred_folder))\n",
    "    target_images = sorted(os.listdir(target_folder))\n",
    "\n",
    "    # Ensure both folders have the same number of images\n",
    "    #if len(pred_images) != len(target_images):\n",
    "     #   raise ValueError(\"Prediction and target folders have different number of images.\")\n",
    "\n",
    "    for pred_img_name, target_img_name in tqdm(zip(pred_images, target_images), total=len(pred_images), desc=\"Calculating PSNR\"):\n",
    "        pred_path = os.path.join(pred_folder, pred_img_name)\n",
    "        target_path = os.path.join(target_folder, target_img_name)\n",
    "\n",
    "        # Open images and convert to RGB\n",
    "        pred_img = Image.open(pred_path).convert('RGB')\n",
    "        target_img = Image.open(target_path).convert('RGB')\n",
    "\n",
    "        # Convert images to tensors and normalize\n",
    "        pred_tensor = torch.from_numpy(np.array(pred_img)).float() / 255.0\n",
    "        target_tensor = torch.from_numpy(np.array(target_img)).float() / 255.0\n",
    "\n",
    "        # Ensure the dimensions are [C, H, W]\n",
    "        pred_tensor = pred_tensor.permute(2, 0, 1).to(device)\n",
    "        target_tensor = target_tensor.permute(2, 0, 1).to(device)\n",
    "\n",
    "        # Upscale the predicted image if upscale_factor > 1\n",
    "        if upscale_factor > 1:\n",
    "            # Add batch dimension: [1, C, H, W]\n",
    "            pred_tensor = pred_tensor.unsqueeze(0)\n",
    "\n",
    "            # Perform upscaling\n",
    "            pred_tensor = F.interpolate(pred_tensor, scale_factor=upscale_factor, mode='bicubic', align_corners=False)\n",
    "\n",
    "            # Remove batch dimension: [C, H, W]\n",
    "            pred_tensor = pred_tensor.squeeze(0)\n",
    "\n",
    "        # Compute PSNR\n",
    "        psnr_value = psnr(pred_tensor, target_tensor, max_val=1.0)\n",
    "        total_psnr += psnr_value\n",
    "        total_images += 1\n",
    "\n",
    "    # Compute average PSNR\n",
    "    avg_psnr = total_psnr / total_images\n",
    "    return avg_psnr\n",
    "\n",
    "# Define folder paths\n",
    "pred_folder_resShift = \"/home/vittorio/Documenti/Upsampling_CFD/results/test_DAT_x2_outdoor_no_umass/visualization/test_set_physic\"\n",
    "pred_folder_bicubic_downsampled = '/home/vittorio/Scrivania/ETH/Upsampling/Upsampling_CFD/datasets/Split_Outdoor_Flow/test/low_res'\n",
    "target_folder_resShift = '/home/vittorio/Scrivania/ETH/Upsampling/Upsampling_CFD/datasets/Split_Outdoor_Flow/test/high_res'\n",
    "# The target_folder_resShift is the same for bicubic as it's the high-resolution images\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Calculate PSNR for the model's output (ResShift)\n",
    "avg_psnr_resShift = calculate_psnr_from_folders(\n",
    "    pred_folder=pred_folder_resShift,\n",
    "    target_folder=target_folder_resShift,\n",
    "    upscale_factor=1,  # No upscaling needed for model outputs\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Calculate PSNR for Bicubic upscaled images\n",
    "# Since pred_folder_bicubic_downsampled contains downsampled images, we upscale them by a factor of 4\n",
    "avg_psnr_bicubic = calculate_psnr_from_folders(\n",
    "    pred_folder=pred_folder_bicubic_downsampled,\n",
    "    target_folder=target_folder_resShift,\n",
    "    upscale_factor=2,  # Upscale by a factor of 4\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"Validation PSNR - Model Output (ResShift): {avg_psnr_resShift:.2f} dB\")\n",
    "print(f\"Validation PSNR - Bicubic Upscaling: {avg_psnr_bicubic:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating SSIM: 100%|██████████| 193/193 [00:01<00:00, 144.47it/s]\n",
      "Calculating SSIM: 100%|██████████| 193/193 [00:00<00:00, 254.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation SSIM - Model Output (ResShift): 0.9793\n",
      "Validation SSIM - Bicubic Upscaling: 0.8704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "\n",
    "def ssim(pred, target, C1=0.01**2, C2=0.03**2):\n",
    "    mu_x = F.conv2d(pred, weight=torch.ones([pred.shape[1], 1, 11, 11]).to(pred.device) / 121, padding=5, groups=pred.shape[1])\n",
    "    mu_y = F.conv2d(target, weight=torch.ones([target.shape[1], 1, 11, 11]).to(target.device) / 121, padding=5, groups=target.shape[1])\n",
    "\n",
    "    sigma_x = F.conv2d(pred * pred, weight=torch.ones([pred.shape[1], 1, 11, 11]).to(pred.device) / 121, padding=5, groups=pred.shape[1]) - mu_x ** 2\n",
    "    sigma_y = F.conv2d(target * target, weight=torch.ones([target.shape[1], 1, 11, 11]).to(target.device) / 121, padding=5, groups=target.shape[1]) - mu_y ** 2\n",
    "    sigma_xy = F.conv2d(pred * target, weight=torch.ones([pred.shape[1], 1, 11, 11]).to(pred.device) / 121, padding=5, groups=pred.shape[1]) - mu_x * mu_y\n",
    "\n",
    "    ssim_n = (2 * mu_x * mu_y + C1) * (2 * sigma_xy + C2)\n",
    "    ssim_d = (mu_x ** 2 + mu_y ** 2 + C1) * (sigma_x + sigma_y + C2)\n",
    "\n",
    "    ssim = ssim_n / ssim_d\n",
    "    return ssim.mean()\n",
    "\n",
    "def calculate_ssim_from_folders(pred_folder, target_folder, upscale_factor=1, device='cpu'):\n",
    "    \"\"\"\n",
    "    Calculate the average SSIM between images in two folders.\n",
    "\n",
    "    Args:\n",
    "        pred_folder (str): Path to the folder containing predicted/downsampled images.\n",
    "        target_folder (str): Path to the folder containing target high-resolution images.\n",
    "        upscale_factor (int, optional): Factor by which to upscale the predicted images.\n",
    "                                        Defaults to 1 (no upscaling).\n",
    "        device (torch.device, optional): Device to perform computations on. Defaults to 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        float: Average SSIM value.\n",
    "    \"\"\"\n",
    "    total_ssim = 0.0\n",
    "    total_images = 0\n",
    "\n",
    "    # Get sorted lists of image filenames\n",
    "    pred_images = sorted(os.listdir(pred_folder))\n",
    "    target_images = sorted(os.listdir(target_folder))\n",
    "\n",
    "    # Ensure both folders have the same number of images\n",
    "    if len(pred_images) != len(target_images):\n",
    "        raise ValueError(\"Prediction and target folders have different number of images.\")\n",
    "\n",
    "    for pred_img_name, target_img_name in tqdm(zip(pred_images, target_images), total=len(pred_images), desc=\"Calculating SSIM\"):\n",
    "        pred_path = os.path.join(pred_folder, pred_img_name)\n",
    "        target_path = os.path.join(target_folder, target_img_name)\n",
    "\n",
    "        # Open images and convert to RGB\n",
    "        pred_img = Image.open(pred_path).convert('RGB')\n",
    "        target_img = Image.open(target_path).convert('RGB')\n",
    "\n",
    "        # Convert images to tensors and normalize\n",
    "        pred_tensor = torch.from_numpy(np.array(pred_img)).float() / 255.0\n",
    "        target_tensor = torch.from_numpy(np.array(target_img)).float() / 255.0\n",
    "\n",
    "        # Ensure the dimensions are [C, H, W]\n",
    "        pred_tensor = pred_tensor.permute(2, 0, 1).to(device)  # Shape: [C, H, W]\n",
    "        target_tensor = target_tensor.permute(2, 0, 1).to(device)  # Shape: [C, H, W]\n",
    "\n",
    "        # Upscale the predicted image if upscale_factor > 1 using PyTorch's interpolate\n",
    "        if upscale_factor > 1:\n",
    "            # Add batch dimension: [1, C, H, W]\n",
    "            pred_tensor = pred_tensor.unsqueeze(0)\n",
    "\n",
    "            # Calculate new spatial dimensions based on upscale_factor\n",
    "            # Alternatively, you can use scale_factor=upscale_factor in interpolate\n",
    "            # but here we ensure it matches the target dimensions\n",
    "            target_height, target_width = target_tensor.shape[1], target_tensor.shape[2]\n",
    "            pred_tensor = F.interpolate(pred_tensor, size=(target_height, target_width), mode='bicubic', align_corners=False)\n",
    "\n",
    "            # Remove batch dimension: [C, H, W]\n",
    "            pred_tensor = pred_tensor.squeeze(0)\n",
    "\n",
    "        # Add batch dimension for SSIM function: [1, C, H, W]\n",
    "        pred_tensor = pred_tensor.unsqueeze(0)\n",
    "        target_tensor = target_tensor.unsqueeze(0)\n",
    "\n",
    "        # Compute SSIM\n",
    "        with torch.no_grad():\n",
    "            ssim_value = ssim(pred_tensor, target_tensor).item()\n",
    "        total_ssim += ssim_value\n",
    "        total_images += 1\n",
    "\n",
    "    # Compute average SSIM\n",
    "    avg_ssim = total_ssim / total_images\n",
    "    return avg_ssim\n",
    "\n",
    "# Define folder paths\n",
    "# Define folder paths\n",
    "pred_folder_resShift = \"/home/vittorio/Scrivania/ETH/Upsampling/Upsampling_CFD/results/swinir_classical_sr_x2\"\n",
    "pred_folder_bicubic_downsampled = '/home/vittorio/Scrivania/ETH/Upsampling/Upsampling_CFD/datasets/Split_Outdoor_Flow/test/low_res'\n",
    "target_folder_resShift = '/home/vittorio/Scrivania/ETH/Upsampling/Upsampling_CFD/datasets/Split_Outdoor_Flow/test/high_res'\n",
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Calculate SSIM for the model's output (ResShift)\n",
    "avg_ssim_resShift = calculate_ssim_from_folders(\n",
    "    pred_folder=pred_folder_resShift,\n",
    "    target_folder=target_folder_resShift,\n",
    "    upscale_factor=1,  # No upscaling needed for model outputs\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Calculate SSIM for Bicubic upscaled images\n",
    "avg_ssim_bicubic = calculate_ssim_from_folders(\n",
    "    pred_folder=pred_folder_bicubic_downsampled,\n",
    "    target_folder=target_folder_resShift,\n",
    "    upscale_factor=2,  # Upscale by a factor of 4\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\nValidation SSIM - Model Output (ResShift): {avg_ssim_resShift:.4f}\")\n",
    "print(f\"Validation SSIM - Bicubic Upscaling: {avg_ssim_bicubic:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Upsampling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
