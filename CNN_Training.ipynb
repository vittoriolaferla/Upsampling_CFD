{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "R7oQaf9A05mR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import make_grid\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "MW4gz3eYLnNU"
      },
      "outputs": [],
      "source": [
        "class UNetForUpsampling(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNetForUpsampling, self).__init__()\n",
        "        self.encoder1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.encoder2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Only two encoder stages due to smaller input size\n",
        "        self.middle = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.decoder2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Adjusting the decoder to match the target upsampling size\n",
        "        self.decoder1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128*2, 64, kernel_size=2, stride=2),  # kernel size and stride adjusted for upscaling\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Final layer to upscale from current size to desired 48x48 output\n",
        "        self.upsample = nn.Upsample(size=(256, 256), mode='bicubic', align_corners=False)\n",
        "        self.final = nn.Conv2d(128, 3, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.encoder1(x)\n",
        "        x2 = self.encoder2(x1)\n",
        "\n",
        "        xm = self.middle(x2)\n",
        "\n",
        "        d2 = self.decoder2(xm)\n",
        "        d2 = torch.cat((x2, d2), dim=1)  # Skip connection\n",
        "        d1 = self.decoder1(d2)\n",
        "        d1 = torch.cat((x1, d1), dim=1)  # Skip connection\n",
        "\n",
        "        upsampled = self.upsample(d1)  # Upsample to target size\n",
        "        out = self.final(upsampled)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "o8eIFQIAxHFO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "\n",
        "# -------- Dataset Definition --------\n",
        "class ImagePairDataset(Dataset):\n",
        "    def __init__(self, lr_folder, hr_folder, lr_transform=None, hr_transform=None):\n",
        "        self.lr_folder = lr_folder\n",
        "        self.hr_folder = hr_folder\n",
        "        self.lr_transform = lr_transform\n",
        "        self.hr_transform = hr_transform\n",
        "\n",
        "        # Only use image names that are in both folders\n",
        "        self.image_names = list(set(os.listdir(lr_folder)) & set(os.listdir(hr_folder)))\n",
        "        self.image_names = [img for img in self.image_names if img.endswith('.png')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.image_names[idx]\n",
        "        lr_image_path = os.path.join(self.lr_folder, image_name)\n",
        "        hr_image_path = os.path.join(self.hr_folder, image_name)\n",
        "\n",
        "        lr_image = Image.open(lr_image_path).convert('RGB')\n",
        "        hr_image = Image.open(hr_image_path).convert('RGB')\n",
        "\n",
        "        if self.lr_transform:\n",
        "            lr_image = self.lr_transform(lr_image)\n",
        "        if self.hr_transform:\n",
        "            hr_image = self.hr_transform(hr_image)\n",
        "\n",
        "        return lr_image, hr_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# -------- Folder Paths --------\n",
        "folder_path_train_hr = '/home/vittorio/Documenti/Upsampling_CFD/datasets/SplitDatasetOutdoorFlow/train/high_res'\n",
        "folder_path_train_lr = '/home/vittorio/Documenti/Upsampling_CFD/datasets/SplitDatasetOutdoorFlow/train/low_res'\n",
        "folder_path_val_hr =  '/home/vittorio/Documenti/Upsampling_CFD/datasets/SplitDatasetOutdoorFlow/test/high_res'\n",
        "folder_path_val_lr ='/home/vittorio/Documenti/Upsampling_CFD/datasets/SplitDatasetOutdoorFlow/test/low_res'\n",
        "\n",
        "# -------- Transforms --------\n",
        "lr_transform = transforms.Compose([\n",
        "    #transforms.Resize((16, 16)),  # Adjust as needed\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "hr_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Assumes HR is already at correct resolution\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu4HK97nSx2J",
        "outputId": "678b2deb-3040-4b73-e2f6-ddf510561198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Dataset Size: 772\n",
            "Test Dataset Size: 192\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# -------- Create Datasets --------\n",
        "full_train_dataset = ImagePairDataset(folder_path_train_lr, folder_path_train_hr,\n",
        "                                      lr_transform=lr_transform, hr_transform=hr_transform)\n",
        "\n",
        "test_dataset = ImagePairDataset(folder_path_val_lr, folder_path_val_hr,\n",
        "                                 lr_transform=lr_transform, hr_transform=hr_transform)\n",
        "\n",
        "# -------- DataLoaders --------\n",
        "train_loader = DataLoader(full_train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# -------- Print Stats --------\n",
        "print(f\"Train Dataset Size: {len(full_train_dataset)}\")\n",
        "print(f\"Test Dataset Size: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqH2O3S3N2kW",
        "outputId": "2d3862d2-dcb3-40c4-f18b-d1b77198a081"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏         | 1/80 [00:08<11:39,  8.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/80], Train Loss: 0.1209, Val Loss: 0.0150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▎         | 2/80 [00:16<10:56,  8.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/80], Train Loss: 0.0077, Val Loss: 0.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 3/80 [00:25<10:56,  8.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/80], Train Loss: 0.0032, Val Loss: 0.0024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 4/80 [00:34<10:46,  8.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/80], Train Loss: 0.0021, Val Loss: 0.0017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▋         | 5/80 [00:42<10:39,  8.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/80], Train Loss: 0.0015, Val Loss: 0.0013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 6/80 [00:51<10:32,  8.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/80], Train Loss: 0.0012, Val Loss: 0.0011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 7/80 [00:59<10:21,  8.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/80], Train Loss: 0.0010, Val Loss: 0.0009\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 8/80 [01:08<10:13,  8.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/80], Train Loss: 0.0009, Val Loss: 0.0008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█▏        | 9/80 [01:16<10:06,  8.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/80], Train Loss: 0.0008, Val Loss: 0.0008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▎        | 10/80 [01:25<10:00,  8.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/80], Train Loss: 0.0007, Val Loss: 0.0007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 11/80 [01:34<09:57,  8.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/80], Train Loss: 0.0007, Val Loss: 0.0007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 12/80 [01:43<09:56,  8.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/80], Train Loss: 0.0007, Val Loss: 0.0007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▋        | 13/80 [01:52<10:00,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/80], Train Loss: 0.0006, Val Loss: 0.0006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 14/80 [02:01<09:56,  9.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [14/80], Train Loss: 0.0006, Val Loss: 0.0006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 15/80 [02:10<09:46,  9.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [15/80], Train Loss: 0.0006, Val Loss: 0.0006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 16/80 [02:20<09:45,  9.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [16/80], Train Loss: 0.0006, Val Loss: 0.0006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 17/80 [02:29<09:34,  9.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [17/80], Train Loss: 0.0006, Val Loss: 0.0006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▎       | 18/80 [02:39<09:35,  9.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [18/80], Train Loss: 0.0006, Val Loss: 0.0006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 19/80 [02:48<09:26,  9.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [19/80], Train Loss: 0.0006, Val Loss: 0.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 20/80 [02:57<09:19,  9.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [20/80], Train Loss: 0.0005, Val Loss: 0.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 21/80 [03:07<09:14,  9.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [21/80], Train Loss: 0.0005, Val Loss: 0.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 22/80 [03:16<09:08,  9.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [22/80], Train Loss: 0.0005, Val Loss: 0.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 23/80 [03:26<08:57,  9.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [23/80], Train Loss: 0.0005, Val Loss: 0.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 24/80 [03:35<08:46,  9.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [24/80], Train Loss: 0.0005, Val Loss: 0.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███▏      | 25/80 [03:45<08:36,  9.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [25/80], Train Loss: 0.0005, Val Loss: 0.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▎      | 26/80 [03:54<08:28,  9.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [26/80], Train Loss: 0.0005, Val Loss: 0.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 27/80 [04:03<08:19,  9.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [27/80], Train Loss: 0.0005, Val Loss: 0.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 28/80 [04:13<08:12,  9.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [28/80], Train Loss: 0.0005, Val Loss: 0.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▋      | 29/80 [04:23<08:08,  9.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [29/80], Train Loss: 0.0005, Val Loss: 0.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 30/80 [04:33<08:03,  9.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [30/80], Train Loss: 0.0005, Val Loss: 0.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 31/80 [04:42<07:53,  9.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [31/80], Train Loss: 0.0005, Val Loss: 0.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 32/80 [04:52<07:41,  9.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [32/80], Train Loss: 0.0005, Val Loss: 0.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████▏     | 33/80 [05:01<07:30,  9.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [33/80], Train Loss: 0.0005, Val Loss: 0.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▎     | 34/80 [05:11<07:18,  9.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [34/80], Train Loss: 0.0005, Val Loss: 0.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 35/80 [05:20<07:07,  9.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [35/80], Train Loss: 0.0005, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 36/80 [05:30<06:59,  9.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [36/80], Train Loss: 0.0005, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▋     | 37/80 [05:39<06:50,  9.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [37/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 38/80 [05:49<06:42,  9.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [38/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 39/80 [05:59<06:31,  9.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [39/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 40/80 [06:08<06:20,  9.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [40/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████▏    | 41/80 [06:18<06:12,  9.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [41/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▎    | 42/80 [06:27<06:03,  9.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [42/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 43/80 [06:37<05:53,  9.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [43/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 44/80 [06:46<05:43,  9.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [44/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▋    | 45/80 [06:56<05:33,  9.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [45/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▊    | 46/80 [07:05<05:25,  9.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [46/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 47/80 [07:15<05:16,  9.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [47/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 48/80 [07:25<05:06,  9.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [48/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████▏   | 49/80 [07:34<04:58,  9.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [49/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▎   | 50/80 [07:44<04:47,  9.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [50/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 51/80 [07:53<04:38,  9.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [51/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 52/80 [08:03<04:27,  9.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [52/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▋   | 53/80 [08:13<04:18,  9.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [53/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 54/80 [08:22<04:09,  9.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [54/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▉   | 55/80 [08:32<04:01,  9.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [55/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 56/80 [08:42<03:53,  9.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [56/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 57/80 [08:52<03:46,  9.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [57/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▎  | 58/80 [09:02<03:39,  9.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [58/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 59/80 [09:12<03:29, 10.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [59/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 60/80 [09:22<03:18,  9.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [60/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 61/80 [09:32<03:08,  9.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [61/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 62/80 [09:42<02:58,  9.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [62/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 63/80 [09:52<02:47,  9.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [63/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 64/80 [10:01<02:36,  9.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [64/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|████████▏ | 65/80 [10:11<02:25,  9.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [65/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▎ | 66/80 [10:21<02:15,  9.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [66/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 67/80 [10:30<02:06,  9.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [67/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 68/80 [10:40<01:56,  9.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [68/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▋ | 69/80 [10:50<01:47,  9.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [69/80], Train Loss: 0.0004, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 70/80 [11:00<01:37,  9.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [70/80], Train Loss: 0.0004, Val Loss: 0.0003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 71/80 [11:10<01:28,  9.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [71/80], Train Loss: 0.0003, Val Loss: 0.0003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 72/80 [11:19<01:17,  9.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [72/80], Train Loss: 0.0003, Val Loss: 0.0003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████▏| 73/80 [11:29<01:08,  9.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [73/80], Train Loss: 0.0004, Val Loss: 0.0003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▎| 74/80 [11:39<00:58,  9.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [74/80], Train Loss: 0.0003, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 75/80 [11:48<00:48,  9.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [75/80], Train Loss: 0.0003, Val Loss: 0.0003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 76/80 [11:58<00:38,  9.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [76/80], Train Loss: 0.0003, Val Loss: 0.0004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 77/80 [12:08<00:28,  9.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [77/80], Train Loss: 0.0003, Val Loss: 0.0003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 78/80 [12:17<00:19,  9.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [78/80], Train Loss: 0.0003, Val Loss: 0.0003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 79/80 [12:27<00:09,  9.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [79/80], Train Loss: 0.0003, Val Loss: 0.0003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [12:37<00:00,  9.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [80/80], Train Loss: 0.0003, Val Loss: 0.0003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 80\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "# model = UpsampleDiffusionModel().to(device)\n",
        "model = UNetForUpsampling().to(device)\n",
        "# model = UNetForUpsamplingGELU().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    # Training phase\n",
        "    total_train_loss = 0\n",
        "    for lr_imgs, hr_imgs in train_loader:\n",
        "        lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(lr_imgs)\n",
        "        loss = criterion(outputs, hr_imgs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_train_loss += loss.item()\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    total_val_loss = 0\n",
        "    with torch.no_grad():  # No gradients needed for validation\n",
        "        for lr_imgs, hr_imgs in test_loader:\n",
        "            lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
        "            outputs = model(lr_imgs)\n",
        "            loss = criterion(outputs, hr_imgs)\n",
        "            total_val_loss += loss.item()\n",
        "    avg_val_loss = total_val_loss / len(test_loader)\n",
        "\n",
        "    # Save the average losses\n",
        "    train_losses.append(avg_train_loss)\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6aln5WVROuBj",
        "outputId": "928a9219-6128-4241-cd1b-22d549e5dfc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation PSNR - Model Output: 34.91\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def psnr(pred, target, max_val=1.0):\n",
        "    mse = F.mse_loss(pred, target)\n",
        "    return 20 * torch.log10(max_val / torch.sqrt(mse))\n",
        "\n",
        "def calculate_average_psnr(data_loader, model, device):\n",
        "    total_psnr_model = 0.0\n",
        "    total_batches = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for lr_imgs, hr_imgs in data_loader:\n",
        "            lr_imgs = lr_imgs.to(device)\n",
        "            hr_imgs = hr_imgs.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            sr_imgs = model(lr_imgs)\n",
        "\n",
        "            # Optional visualization (only on the first sample in batch)\n",
        "            # visualize_sr_vs_hr(sr_imgs[0].cpu(), hr_imgs[0].cpu())\n",
        "\n",
        "            # Compute PSNR directly\n",
        "            psnr_model = psnr(sr_imgs, hr_imgs).item()\n",
        "            total_psnr_model += psnr_model\n",
        "            total_batches += 1\n",
        "\n",
        "    avg_psnr_model = total_psnr_model / total_batches\n",
        "    return avg_psnr_model\n",
        "\n",
        "val_psnr_model = calculate_average_psnr(test_loader, model, device)\n",
        "print(f\"Validation PSNR - Model Output: {val_psnr_model:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "p7xVVMdtx5XL",
        "outputId": "54163c1f-b6c1-4a2e-9248-20565370ed15"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (512) must match the size of tensor b (256) at non-singleton dimension 3",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-fdca919e69c8>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mval_ssim_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ssim_bicubic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_average_ssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation SSIM - Model Output: {val_ssim_model:.4f}, Bicubic: {val_ssim_bicubic:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-fdca919e69c8>\u001b[0m in \u001b[0;36mcalculate_average_ssim\u001b[0;34m(data_loader, model, device)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# Compute SSIM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mssim_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mssim_bicubic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbicubic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mtotal_ssim_model\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mssim_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-fdca919e69c8>\u001b[0m in \u001b[0;36mssim\u001b[0;34m(pred, target, C1, C2)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0msigma_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu_pred\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0msigma_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu_target\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0msigma_cross\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu_pred\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmu_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# SSIM formula\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (256) at non-singleton dimension 3"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def ssim(pred, target, C1=0.01**2, C2=0.03**2):\n",
        "    \"\"\"Structural Similarity Index Measure (SSIM) for image batches.\"\"\"\n",
        "    # Assumes pred and target are shape (B, C, H, W)\n",
        "    B, C, H, W = pred.size()\n",
        "\n",
        "    # Create a Gaussian filter manually (uniform box blur here for simplicity)\n",
        "    kernel = torch.ones((C, 1, 11, 11), device=pred.device) / 121\n",
        "\n",
        "    # Compute means\n",
        "    mu_pred = F.conv2d(pred, kernel, padding=5, groups=C)\n",
        "    mu_target = F.conv2d(target, kernel, padding=5, groups=C)\n",
        "\n",
        "    # Compute variances and covariance\n",
        "    sigma_pred = F.conv2d(pred * pred, kernel, padding=5, groups=C) - mu_pred ** 2\n",
        "    sigma_target = F.conv2d(target * target, kernel, padding=5, groups=C) - mu_target ** 2\n",
        "    sigma_cross = F.conv2d(pred * target, kernel, padding=5, groups=C) - mu_pred * mu_target\n",
        "\n",
        "    # SSIM formula\n",
        "    numerator = (2 * mu_pred * mu_target + C1) * (2 * sigma_cross + C2)\n",
        "    denominator = (mu_pred ** 2 + mu_target ** 2 + C1) * (sigma_pred + sigma_target + C2)\n",
        "    ssim_map = numerator / denominator\n",
        "\n",
        "    return ssim_map.mean()\n",
        "\n",
        "def calculate_average_ssim(data_loader, model, device):\n",
        "    total_ssim_model = 0.0\n",
        "    total_ssim_bicubic = 0.0\n",
        "    total_batches = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for lr_imgs, hr_imgs in data_loader:\n",
        "            lr_imgs = lr_imgs.to(device)\n",
        "            hr_imgs = hr_imgs.to(device)\n",
        "\n",
        "            # Get model output\n",
        "            sr_imgs = model(lr_imgs)\n",
        "            sr_imgs = torch.clamp(sr_imgs, 0.0, 1.0)\n",
        "\n",
        "            # Bicubic baseline\n",
        "            bicubic = F.interpolate(lr_imgs, scale_factor=4, mode='bicubic', align_corners=False)\n",
        "            bicubic = torch.clamp(bicubic, 0.0, 1.0)\n",
        "\n",
        "            # Compute SSIM\n",
        "            ssim_model = ssim(sr_imgs, hr_imgs).item()\n",
        "            ssim_bicubic = ssim(bicubic, hr_imgs).item()\n",
        "\n",
        "            total_ssim_model += ssim_model\n",
        "            total_ssim_bicubic += ssim_bicubic\n",
        "            total_batches += 1\n",
        "\n",
        "    avg_ssim_model = total_ssim_model / total_batches\n",
        "    avg_ssim_bicubic = total_ssim_bicubic / total_batches\n",
        "    return avg_ssim_model, avg_ssim_bicubic\n",
        "\n",
        "\n",
        "val_ssim_model, val_ssim_bicubic = calculate_average_ssim(test_loader, model, device)\n",
        "print(f\"Validation SSIM - Model Output: {val_ssim_model:.4f}, Bicubic: {val_ssim_bicubic:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2wmXhDJTqd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation RMSE - Model Output: 0.0402, Bicubic: 0.0607\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_rmse(pred, target):\n",
        "    \"\"\"\n",
        "    Compute Root Mean Squared Error (RMSE) between prediction and ground truth.\n",
        "    Assumes both are tensors in [0, 1] and of shape (B, C, H, W).\n",
        "    \"\"\"\n",
        "    mse = F.mse_loss(pred, target)\n",
        "    return torch.sqrt(mse).item()\n",
        "\n",
        "def calculate_average_rmse(data_loader, model, device):\n",
        "    \"\"\"\n",
        "    Compute average RMSE for model predictions and bicubic interpolation over a dataset.\n",
        "    \"\"\"\n",
        "    total_rmse_model = 0.0\n",
        "    total_rmse_bicubic = 0.0\n",
        "    total_batches = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for lr_imgs, hr_imgs in data_loader:\n",
        "            lr_imgs = lr_imgs.to(device)\n",
        "            hr_imgs = hr_imgs.to(device)\n",
        "\n",
        "            # Model prediction\n",
        "            sr_imgs = model(lr_imgs)\n",
        "            sr_imgs = torch.clamp(sr_imgs, 0.0, 1.0)\n",
        "\n",
        "            # Bicubic interpolation baseline\n",
        "            bicubic = F.interpolate(lr_imgs, scale_factor=4, mode='bicubic', align_corners=False)\n",
        "            bicubic = torch.clamp(bicubic, 0.0, 1.0)\n",
        "\n",
        "            # Compute RMSEs\n",
        "            rmse_model = compute_rmse(sr_imgs, hr_imgs)\n",
        "            rmse_bicubic = compute_rmse(bicubic, hr_imgs)\n",
        "\n",
        "            total_rmse_model += rmse_model\n",
        "            total_rmse_bicubic += rmse_bicubic\n",
        "            total_batches += 1\n",
        "\n",
        "    avg_rmse_model = total_rmse_model / total_batches\n",
        "    avg_rmse_bicubic = total_rmse_bicubic / total_batches\n",
        "\n",
        "    return avg_rmse_model, avg_rmse_bicubic\n",
        "\n",
        "# Assuming your DataLoaders and model are ready\n",
        "val_rmse_model, val_rmse_bicubic = calculate_average_rmse(test_loader, model, device)\n",
        "\n",
        "print(f\"Validation RMSE - Model Output: {val_rmse_model:.4f}, Bicubic: {val_rmse_bicubic:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_images_from_dataset(dataset_type='test', batch_num=0, num_images=4, first_image=0):\n",
        "    # Select the appropriate DataLoader\n",
        "    if dataset_type == 'train':\n",
        "        selected_loader = train_loader\n",
        "    elif dataset_type == 'val':\n",
        "        selected_loader = val_loader\n",
        "    else:\n",
        "        raise ValueError(\"Invalid dataset type. Choose 'train', 'val', or 'test'.\")\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    current_batch = 0\n",
        "    with torch.no_grad():  # Inference without gradient calculation\n",
        "        for lr_imgs, hr_imgs in selected_loader:\n",
        "            if current_batch == batch_num:\n",
        "                lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
        "                outputs = model(lr_imgs)\n",
        "                bicubic = torch.nn.functional.interpolate(lr_imgs, scale_factor=2, mode='bicubic', align_corners=False)\n",
        "                break  # Exit loop after processing the specified batch\n",
        "            current_batch += 1\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(min(num_images, lr_imgs.size(0))):  # Ensure not to exceed batch size\n",
        "        # Plotting code remains the same as before\n",
        "        # Low-resolution images\n",
        "        plt.subplot(4, num_images, i+1)\n",
        "        plt.imshow(lr_imgs[i+first_image].permute(1, 2, 0).cpu().detach().numpy())\n",
        "        plt.title('Low-Res')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # High-resolution (Ground Truth)\n",
        "        plt.subplot(4, num_images, num_images+i+1)\n",
        "        plt.imshow(hr_imgs[i+first_image].permute(1, 2, 0).cpu().detach().numpy())\n",
        "        plt.title('High-Res')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Model output\n",
        "        plt.subplot(4, num_images, 2*num_images+i+1)\n",
        "        plt.imshow(outputs[i+first_image].permute(1, 2, 0).cpu().detach().numpy())\n",
        "        plt.title('Output')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Bicubic upsampled\n",
        "        plt.subplot(4, num_images, 3*num_images+i+1)\n",
        "        plt.imshow(bicubic[i+first_image].permute(1, 2, 0).cpu().detach().numpy())\n",
        "        plt.title('Bicubic')\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "show_images_from_dataset(dataset_type='val', batch_num=3, num_images=4, first_image=20)\n",
        "print(f\"Number of batches in Training DataLoader: {len(train_loader)}\")\n",
        "print(f\"Number of batches in Validation DataLoader: {len(val_loader)}\")\n",
        "print(lr_imgs.size())\n",
        "print(hr_imgs.size())\n",
        "print(outputs.size())\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Upsampling",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
