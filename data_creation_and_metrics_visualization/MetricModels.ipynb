{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed: XZ_16_33_suffix.png -> XZ_16_33.png\n",
      "Renamed: XZ_47_39_suffix.png -> XZ_47_39.png\n",
      "Renamed: XZ_4_36_suffix.png -> XZ_4_36.png\n",
      "Renamed: XZ_35_40_suffix.png -> XZ_35_40.png\n",
      "Renamed: XZ_62_39_suffix.png -> XZ_62_39.png\n",
      "Renamed: XZ_73_35_suffix.png -> XZ_73_35.png\n",
      "Renamed: XZ_21_40_suffix.png -> XZ_21_40.png\n",
      "Renamed: XZ_103_35_suffix.png -> XZ_103_35.png\n",
      "Renamed: XZ_83_35_suffix.png -> XZ_83_35.png\n",
      "Renamed: XZ_18_32_suffix.png -> XZ_18_32.png\n",
      "Renamed: XZ_83_40_suffix.png -> XZ_83_40.png\n",
      "Renamed: XZ_83_38_suffix.png -> XZ_83_38.png\n",
      "Renamed: XZ_109_32_suffix.png -> XZ_109_32.png\n",
      "Renamed: XZ_113_39_suffix.png -> XZ_113_39.png\n",
      "Renamed: XZ_124_38_suffix.png -> XZ_124_38.png\n",
      "Renamed: XZ_70_34_suffix.png -> XZ_70_34.png\n",
      "Renamed: XZ_60_31_suffix.png -> XZ_60_31.png\n",
      "Renamed: XZ_93_31_suffix.png -> XZ_93_31.png\n",
      "Renamed: XZ_55_35_suffix.png -> XZ_55_35.png\n",
      "Renamed: XZ_58_39_suffix.png -> XZ_58_39.png\n",
      "Renamed: XZ_16_37_suffix.png -> XZ_16_37.png\n",
      "Renamed: XZ_62_38_suffix.png -> XZ_62_38.png\n",
      "Renamed: XZ_7_31_suffix.png -> XZ_7_31.png\n",
      "Renamed: XZ_125_40_suffix.png -> XZ_125_40.png\n",
      "Renamed: XZ_26_34_suffix.png -> XZ_26_34.png\n",
      "Renamed: XZ_115_31_suffix.png -> XZ_115_31.png\n",
      "Renamed: XZ_124_36_suffix.png -> XZ_124_36.png\n",
      "Renamed: XZ_38_33_suffix.png -> XZ_38_33.png\n",
      "Renamed: XZ_38_31_suffix.png -> XZ_38_31.png\n",
      "Renamed: XZ_119_31_suffix.png -> XZ_119_31.png\n",
      "Renamed: XZ_10_34_suffix.png -> XZ_10_34.png\n",
      "Renamed: XZ_91_34_suffix.png -> XZ_91_34.png\n",
      "Renamed: XZ_52_38_suffix.png -> XZ_52_38.png\n",
      "Renamed: XZ_23_31_suffix.png -> XZ_23_31.png\n",
      "Renamed: XZ_105_36_suffix.png -> XZ_105_36.png\n",
      "Renamed: XZ_60_36_suffix.png -> XZ_60_36.png\n",
      "Renamed: XZ_22_32_suffix.png -> XZ_22_32.png\n",
      "Renamed: XZ_75_38_suffix.png -> XZ_75_38.png\n",
      "Renamed: XZ_106_39_suffix.png -> XZ_106_39.png\n",
      "Renamed: XZ_117_37_suffix.png -> XZ_117_37.png\n",
      "Renamed: XZ_47_31_suffix.png -> XZ_47_31.png\n",
      "Renamed: XZ_41_35_suffix.png -> XZ_41_35.png\n",
      "Renamed: XZ_76_40_suffix.png -> XZ_76_40.png\n",
      "Renamed: XZ_24_39_suffix.png -> XZ_24_39.png\n",
      "Renamed: XZ_77_32_suffix.png -> XZ_77_32.png\n",
      "Renamed: XZ_28_39_suffix.png -> XZ_28_39.png\n",
      "Renamed: XZ_99_40_suffix.png -> XZ_99_40.png\n",
      "Renamed: XZ_83_39_suffix.png -> XZ_83_39.png\n",
      "Renamed: XZ_5_33_suffix.png -> XZ_5_33.png\n",
      "Renamed: XZ_126_31_suffix.png -> XZ_126_31.png\n",
      "Renamed: XZ_63_38_suffix.png -> XZ_63_38.png\n",
      "Renamed: XZ_8_36_suffix.png -> XZ_8_36.png\n",
      "Renamed: XZ_1_33_suffix.png -> XZ_1_33.png\n",
      "Renamed: XZ_109_40_suffix.png -> XZ_109_40.png\n",
      "Renamed: XZ_70_40_suffix.png -> XZ_70_40.png\n",
      "Renamed: XZ_33_39_suffix.png -> XZ_33_39.png\n",
      "Renamed: XZ_57_39_suffix.png -> XZ_57_39.png\n",
      "Renamed: XZ_28_40_suffix.png -> XZ_28_40.png\n",
      "Renamed: XZ_84_40_suffix.png -> XZ_84_40.png\n",
      "Renamed: XZ_97_36_suffix.png -> XZ_97_36.png\n",
      "Renamed: XZ_114_34_suffix.png -> XZ_114_34.png\n",
      "Renamed: XZ_12_34_suffix.png -> XZ_12_34.png\n",
      "Renamed: XZ_88_31_suffix.png -> XZ_88_31.png\n",
      "Renamed: XZ_41_34_suffix.png -> XZ_41_34.png\n",
      "Renamed: XZ_73_32_suffix.png -> XZ_73_32.png\n",
      "Renamed: XZ_47_32_suffix.png -> XZ_47_32.png\n",
      "Renamed: XZ_12_40_suffix.png -> XZ_12_40.png\n",
      "Renamed: XZ_33_33_suffix.png -> XZ_33_33.png\n",
      "Renamed: XZ_23_39_suffix.png -> XZ_23_39.png\n",
      "Renamed: XZ_119_39_suffix.png -> XZ_119_39.png\n",
      "Renamed: XZ_81_39_suffix.png -> XZ_81_39.png\n",
      "Renamed: XZ_20_35_suffix.png -> XZ_20_35.png\n",
      "Renamed: XZ_50_36_suffix.png -> XZ_50_36.png\n",
      "Renamed: XZ_59_33_suffix.png -> XZ_59_33.png\n",
      "Renamed: XZ_99_38_suffix.png -> XZ_99_38.png\n",
      "Renamed: XZ_113_37_suffix.png -> XZ_113_37.png\n",
      "Renamed: XZ_35_32_suffix.png -> XZ_35_32.png\n",
      "Renamed: XZ_115_35_suffix.png -> XZ_115_35.png\n",
      "Renamed: XZ_55_38_suffix.png -> XZ_55_38.png\n",
      "Renamed: XZ_55_36_suffix.png -> XZ_55_36.png\n",
      "Renamed: XZ_71_39_suffix.png -> XZ_71_39.png\n",
      "Renamed: XZ_37_32_suffix.png -> XZ_37_32.png\n",
      "Renamed: XZ_75_31_suffix.png -> XZ_75_31.png\n",
      "Renamed: XZ_111_36_suffix.png -> XZ_111_36.png\n",
      "Renamed: XZ_97_31_suffix.png -> XZ_97_31.png\n",
      "Renamed: XZ_3_37_suffix.png -> XZ_3_37.png\n",
      "Renamed: XZ_100_31_suffix.png -> XZ_100_31.png\n",
      "Renamed: XZ_125_37_suffix.png -> XZ_125_37.png\n",
      "Renamed: XZ_107_37_suffix.png -> XZ_107_37.png\n",
      "Renamed: XZ_38_40_suffix.png -> XZ_38_40.png\n",
      "Renamed: XZ_104_35_suffix.png -> XZ_104_35.png\n",
      "Renamed: XZ_4_39_suffix.png -> XZ_4_39.png\n",
      "Renamed: XZ_17_31_suffix.png -> XZ_17_31.png\n",
      "Renamed: XZ_24_40_suffix.png -> XZ_24_40.png\n",
      "Renamed: XZ_16_35_suffix.png -> XZ_16_35.png\n",
      "Renamed: XZ_99_37_suffix.png -> XZ_99_37.png\n",
      "Renamed: XZ_14_39_suffix.png -> XZ_14_39.png\n",
      "Renamed: XZ_104_37_suffix.png -> XZ_104_37.png\n",
      "Renamed: XZ_67_31_suffix.png -> XZ_67_31.png\n",
      "Renamed: XZ_122_35_suffix.png -> XZ_122_35.png\n",
      "Renamed: XZ_68_39_suffix.png -> XZ_68_39.png\n",
      "Renamed: XZ_36_39_suffix.png -> XZ_36_39.png\n",
      "Renamed: XZ_117_33_suffix.png -> XZ_117_33.png\n",
      "Renamed: XZ_68_38_suffix.png -> XZ_68_38.png\n",
      "Renamed: XZ_126_39_suffix.png -> XZ_126_39.png\n",
      "Renamed: XZ_66_32_suffix.png -> XZ_66_32.png\n",
      "Renamed: XZ_17_33_suffix.png -> XZ_17_33.png\n",
      "Renamed: XZ_45_31_suffix.png -> XZ_45_31.png\n",
      "Renamed: XZ_87_38_suffix.png -> XZ_87_38.png\n",
      "Renamed: XZ_110_34_suffix.png -> XZ_110_34.png\n",
      "Renamed: XZ_17_39_suffix.png -> XZ_17_39.png\n",
      "Renamed: XZ_40_36_suffix.png -> XZ_40_36.png\n",
      "Renamed: XZ_5_35_suffix.png -> XZ_5_35.png\n",
      "Renamed: XZ_46_39_suffix.png -> XZ_46_39.png\n",
      "Renamed: XZ_58_34_suffix.png -> XZ_58_34.png\n",
      "Renamed: XZ_80_38_suffix.png -> XZ_80_38.png\n",
      "Renamed: XZ_120_32_suffix.png -> XZ_120_32.png\n",
      "Renamed: XZ_116_35_suffix.png -> XZ_116_35.png\n",
      "Renamed: XZ_125_36_suffix.png -> XZ_125_36.png\n",
      "Renamed: XZ_49_34_suffix.png -> XZ_49_34.png\n",
      "Renamed: XZ_109_38_suffix.png -> XZ_109_38.png\n",
      "Renamed: XZ_46_37_suffix.png -> XZ_46_37.png\n",
      "Renamed: XZ_103_40_suffix.png -> XZ_103_40.png\n",
      "Renamed: XZ_98_36_suffix.png -> XZ_98_36.png\n",
      "Renamed: XZ_59_38_suffix.png -> XZ_59_38.png\n",
      "Renamed: XZ_12_37_suffix.png -> XZ_12_37.png\n",
      "Renamed: XZ_42_39_suffix.png -> XZ_42_39.png\n",
      "Renamed: XZ_74_37_suffix.png -> XZ_74_37.png\n",
      "Renamed: XZ_88_38_suffix.png -> XZ_88_38.png\n",
      "Renamed: XZ_18_38_suffix.png -> XZ_18_38.png\n",
      "Renamed: XZ_32_40_suffix.png -> XZ_32_40.png\n",
      "Renamed: XZ_71_38_suffix.png -> XZ_71_38.png\n",
      "Renamed: XZ_9_38_suffix.png -> XZ_9_38.png\n",
      "Renamed: XZ_121_38_suffix.png -> XZ_121_38.png\n",
      "Renamed: XZ_61_40_suffix.png -> XZ_61_40.png\n",
      "Renamed: XZ_23_36_suffix.png -> XZ_23_36.png\n",
      "Renamed: XZ_106_31_suffix.png -> XZ_106_31.png\n",
      "Renamed: XZ_121_35_suffix.png -> XZ_121_35.png\n",
      "Renamed: XZ_126_37_suffix.png -> XZ_126_37.png\n",
      "Renamed: XZ_24_31_suffix.png -> XZ_24_31.png\n",
      "Renamed: XZ_74_32_suffix.png -> XZ_74_32.png\n",
      "Renamed: XZ_20_39_suffix.png -> XZ_20_39.png\n",
      "Renamed: XZ_118_40_suffix.png -> XZ_118_40.png\n",
      "Renamed: XZ_77_38_suffix.png -> XZ_77_38.png\n",
      "Renamed: XZ_43_35_suffix.png -> XZ_43_35.png\n",
      "Renamed: XZ_1_32_suffix.png -> XZ_1_32.png\n",
      "Renamed: XZ_64_36_suffix.png -> XZ_64_36.png\n",
      "Renamed: XZ_41_38_suffix.png -> XZ_41_38.png\n",
      "Renamed: XZ_43_32_suffix.png -> XZ_43_32.png\n",
      "Renamed: XZ_2_35_suffix.png -> XZ_2_35.png\n",
      "Renamed: XZ_88_35_suffix.png -> XZ_88_35.png\n",
      "Renamed: XZ_11_31_suffix.png -> XZ_11_31.png\n",
      "Renamed: XZ_27_38_suffix.png -> XZ_27_38.png\n",
      "Renamed: XZ_93_39_suffix.png -> XZ_93_39.png\n",
      "Renamed: XZ_101_34_suffix.png -> XZ_101_34.png\n",
      "Renamed: XZ_45_35_suffix.png -> XZ_45_35.png\n",
      "Renamed: XZ_78_39_suffix.png -> XZ_78_39.png\n",
      "Renamed: XZ_87_39_suffix.png -> XZ_87_39.png\n",
      "Renamed: XZ_42_32_suffix.png -> XZ_42_32.png\n",
      "Renamed: XZ_114_39_suffix.png -> XZ_114_39.png\n",
      "Renamed: XZ_122_40_suffix.png -> XZ_122_40.png\n",
      "Renamed: XZ_103_34_suffix.png -> XZ_103_34.png\n",
      "Renamed: XZ_74_40_suffix.png -> XZ_74_40.png\n",
      "Renamed: XZ_64_35_suffix.png -> XZ_64_35.png\n",
      "Renamed: XZ_112_31_suffix.png -> XZ_112_31.png\n",
      "Renamed: XZ_91_38_suffix.png -> XZ_91_38.png\n",
      "Renamed: XZ_19_35_suffix.png -> XZ_19_35.png\n",
      "Renamed: XZ_38_36_suffix.png -> XZ_38_36.png\n",
      "Renamed: XZ_86_31_suffix.png -> XZ_86_31.png\n",
      "Renamed: XZ_18_36_suffix.png -> XZ_18_36.png\n",
      "Renamed: XZ_77_37_suffix.png -> XZ_77_37.png\n",
      "Renamed: XZ_101_40_suffix.png -> XZ_101_40.png\n",
      "Renamed: XZ_9_34_suffix.png -> XZ_9_34.png\n",
      "Renamed: XZ_27_35_suffix.png -> XZ_27_35.png\n",
      "Renamed: XZ_32_34_suffix.png -> XZ_32_34.png\n",
      "Renamed: XZ_94_36_suffix.png -> XZ_94_36.png\n",
      "Renamed: XZ_70_32_suffix.png -> XZ_70_32.png\n",
      "Renamed: XZ_117_39_suffix.png -> XZ_117_39.png\n",
      "Renamed: XZ_21_36_suffix.png -> XZ_21_36.png\n",
      "Renamed: XZ_65_35_suffix.png -> XZ_65_35.png\n",
      "Renamed: XZ_92_34_suffix.png -> XZ_92_34.png\n",
      "Renamed: XZ_126_35_suffix.png -> XZ_126_35.png\n",
      "Renamed: XZ_42_33_suffix.png -> XZ_42_33.png\n",
      "Renamed: XZ_87_33_suffix.png -> XZ_87_33.png\n",
      "Renamed: XZ_22_36_suffix.png -> XZ_22_36.png\n",
      "Renamed: XZ_79_40_suffix.png -> XZ_79_40.png\n",
      "Renamed: XZ_76_37_suffix.png -> XZ_76_37.png\n",
      "Renamed: XZ_9_37_suffix.png -> XZ_9_37.png\n",
      "Renamed: XZ_14_38_suffix.png -> XZ_14_38.png\n",
      "Renamed: XZ_35_36_suffix.png -> XZ_35_36.png\n",
      "Renamed: XZ_62_34_suffix.png -> XZ_62_34.png\n",
      "Renamed: XZ_91_31_suffix.png -> XZ_91_31.png\n",
      "Renamed: XZ_65_34_suffix.png -> XZ_65_34.png\n",
      "Renamed: XZ_54_35_suffix.png -> XZ_54_35.png\n",
      "Renamed: XZ_107_32_suffix.png -> XZ_107_32.png\n",
      "Renamed: XZ_12_39_suffix.png -> XZ_12_39.png\n",
      "Renamed: XZ_71_36_suffix.png -> XZ_71_36.png\n",
      "Renamed: XZ_36_33_suffix.png -> XZ_36_33.png\n",
      "Renamed: XZ_39_34_suffix.png -> XZ_39_34.png\n",
      "Renamed: XZ_95_35_suffix.png -> XZ_95_35.png\n",
      "Renamed: XZ_81_31_suffix.png -> XZ_81_31.png\n",
      "Renamed: XZ_53_37_suffix.png -> XZ_53_37.png\n",
      "Renamed: XZ_110_39_suffix.png -> XZ_110_39.png\n",
      "Renamed: XZ_112_38_suffix.png -> XZ_112_38.png\n",
      "Renamed: XZ_89_38_suffix.png -> XZ_89_38.png\n",
      "Renamed: XZ_47_40_suffix.png -> XZ_47_40.png\n",
      "Renamed: XZ_33_37_suffix.png -> XZ_33_37.png\n",
      "Renamed: XZ_66_39_suffix.png -> XZ_66_39.png\n",
      "Renamed: XZ_75_34_suffix.png -> XZ_75_34.png\n",
      "Renamed: XZ_19_37_suffix.png -> XZ_19_37.png\n",
      "Renamed: XZ_120_34_suffix.png -> XZ_120_34.png\n",
      "Renamed: XZ_95_39_suffix.png -> XZ_95_39.png\n",
      "Renamed: XZ_79_37_suffix.png -> XZ_79_37.png\n",
      "Renamed: XZ_3_34_suffix.png -> XZ_3_34.png\n",
      "Renamed: XZ_39_35_suffix.png -> XZ_39_35.png\n",
      "Renamed: XZ_11_32_suffix.png -> XZ_11_32.png\n",
      "Renamed: XZ_52_33_suffix.png -> XZ_52_33.png\n",
      "Renamed: XZ_8_35_suffix.png -> XZ_8_35.png\n",
      "Renamed: XZ_118_39_suffix.png -> XZ_118_39.png\n",
      "Renamed: XZ_102_33_suffix.png -> XZ_102_33.png\n",
      "Renamed: XZ_102_32_suffix.png -> XZ_102_32.png\n",
      "Renamed: XZ_104_39_suffix.png -> XZ_104_39.png\n",
      "Renamed: XZ_47_33_suffix.png -> XZ_47_33.png\n",
      "Renamed: XZ_104_32_suffix.png -> XZ_104_32.png\n",
      "Renamed: XZ_123_36_suffix.png -> XZ_123_36.png\n",
      "Renamed: XZ_50_39_suffix.png -> XZ_50_39.png\n",
      "Renamed: XZ_24_36_suffix.png -> XZ_24_36.png\n",
      "Renamed: XZ_69_35_suffix.png -> XZ_69_35.png\n",
      "Renamed: XZ_60_37_suffix.png -> XZ_60_37.png\n",
      "Renamed: XZ_85_32_suffix.png -> XZ_85_32.png\n",
      "Renamed: XZ_33_40_suffix.png -> XZ_33_40.png\n",
      "Renamed: XZ_121_31_suffix.png -> XZ_121_31.png\n",
      "Renamed: XZ_87_34_suffix.png -> XZ_87_34.png\n",
      "Renamed: XZ_106_37_suffix.png -> XZ_106_37.png\n",
      "Renamed: XZ_108_37_suffix.png -> XZ_108_37.png\n",
      "Renamed: XZ_57_31_suffix.png -> XZ_57_31.png\n",
      "Renamed: XZ_9_31_suffix.png -> XZ_9_31.png\n",
      "Renamed: XZ_105_34_suffix.png -> XZ_105_34.png\n",
      "Renamed: XZ_42_31_suffix.png -> XZ_42_31.png\n",
      "Renamed: XZ_28_38_suffix.png -> XZ_28_38.png\n",
      "Renamed: XZ_54_40_suffix.png -> XZ_54_40.png\n",
      "Renamed: XZ_113_36_suffix.png -> XZ_113_36.png\n",
      "Renamed: XZ_69_39_suffix.png -> XZ_69_39.png\n",
      "Renamed: XZ_23_35_suffix.png -> XZ_23_35.png\n",
      "Renamed: XZ_56_38_suffix.png -> XZ_56_38.png\n",
      "Renamed: XZ_31_37_suffix.png -> XZ_31_37.png\n",
      "Renamed: XZ_53_32_suffix.png -> XZ_53_32.png\n",
      "Renamed: XZ_5_34_suffix.png -> XZ_5_34.png\n",
      "Renamed: XZ_23_38_suffix.png -> XZ_23_38.png\n",
      "Renamed: XZ_19_38_suffix.png -> XZ_19_38.png\n",
      "Renamed: XZ_96_33_suffix.png -> XZ_96_33.png\n",
      "Renamed: XZ_52_40_suffix.png -> XZ_52_40.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the directory containing the images\n",
    "image_folder = \"/home/vittorio/Documenti/Upsampling_CFD/results/test_DAT_x2_outdoor_no_umass/visualization/decoded\"\n",
    "# The suffix you want to remove\n",
    "suffix_to_remove = \"_suffix\"\n",
    "\n",
    "# Get all files in the directory\n",
    "for filename in os.listdir(image_folder):\n",
    "    # Check if it's a file (not a directory) and if it ends with the suffix you want to remove\n",
    "    if os.path.isfile(os.path.join(image_folder, filename)):\n",
    "        # Split the filename into name and extension\n",
    "        file_name, file_ext = os.path.splitext(filename)\n",
    "        \n",
    "        # If the file ends with the suffix, rename it\n",
    "        if file_name.endswith(suffix_to_remove):\n",
    "            new_name = file_name[:-len(suffix_to_remove)] + file_ext\n",
    "            # Rename the file\n",
    "            os.rename(os.path.join(image_folder, filename), os.path.join(image_folder, new_name))\n",
    "            print(f\"Renamed: {filename} -> {new_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating PSNR:   0%|          | 0/252 [00:00<?, ?it/s]<ipython-input-3-68437fa6d575>:20: UserWarning: Using a target size (torch.Size([3, 24, 24])) that is different to the input size (torch.Size([3, 48, 48])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  mse = F.mse_loss(pred, target)\n",
      "Calculating PSNR:   1%|          | 2/252 [00:00<00:02, 110.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /home/vittorio/Documenti/Upsampling_CFD/results/test_DAT_x2_outdoor_no_umass/visualization/decoded/XZ_100_31.png and /home/vittorio/Scrivania/ETH/Upsampling/ResShift_4_scale/data/Scalar_Images/XZ_0_30.png\n",
      "Processing: /home/vittorio/Documenti/Upsampling_CFD/results/test_DAT_x2_outdoor_no_umass/visualization/decoded/XZ_101_34.png and /home/vittorio/Scrivania/ETH/Upsampling/ResShift_4_scale/data/Scalar_Images/XZ_0_30_1.png\n",
      "Processing: /home/vittorio/Documenti/Upsampling_CFD/results/test_DAT_x2_outdoor_no_umass/visualization/decoded/XZ_101_40.png and /home/vittorio/Scrivania/ETH/Upsampling/ResShift_4_scale/data/Scalar_Images/XZ_0_30_2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (48) must match the size of tensor b (24) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-68437fa6d575>\u001b[0m in \u001b[0;36m<cell line: 98>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m# Calculate PSNR for the model's output (ResShift)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m avg_psnr_resShift = calculate_psnr_from_folders(\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mpred_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_folder_resShift\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mtarget_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_folder_resShift\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-68437fa6d575>\u001b[0m in \u001b[0;36mcalculate_psnr_from_folders\u001b[0;34m(pred_folder, target_folder, upscale_factor, device)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# Compute PSNR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mpsnr_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mtotal_psnr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpsnr_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtotal_images\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-68437fa6d575>\u001b[0m in \u001b[0;36mpsnr\u001b[0;34m(pred, target, max_val)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPSNR\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecibels\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Perfect match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Upsampling/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2923\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2925\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2926\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Upsampling/lib/python3.8/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (48) must match the size of tensor b (24) at non-singleton dimension 2"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm  # Ensure tqdm is imported for progress bar\n",
    "\n",
    "def psnr(pred, target, max_val=1.0):\n",
    "    \"\"\"\n",
    "    Compute the Peak Signal-to-Noise Ratio (PSNR) between two images.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): Predicted image tensor of shape [C, H, W].\n",
    "        target (torch.Tensor): Target image tensor of shape [C, H, W].\n",
    "        max_val (float, optional): Maximum possible pixel value. Defaults to 1.0.\n",
    "\n",
    "    Returns:\n",
    "        float: PSNR value in decibels (dB).\n",
    "    \"\"\"\n",
    "    mse = F.mse_loss(pred, target)\n",
    "    if mse == 0:\n",
    "        return float('inf')  # Perfect match\n",
    "    psnr_value = 20 * torch.log10(max_val / torch.sqrt(mse))\n",
    "    return psnr_value.item()\n",
    "\n",
    "def calculate_psnr_from_folders(pred_folder, target_folder, upscale_factor=1, device='cpu'):\n",
    "    \"\"\"\n",
    "    Calculate the average PSNR between images in two folders.\n",
    "\n",
    "    Args:\n",
    "        pred_folder (str): Path to the folder containing predicted/downsampled images.\n",
    "        target_folder (str): Path to the folder containing target high-resolution images.\n",
    "        upscale_factor (int, optional): Factor by which to upscale the predicted images.\n",
    "                                        Defaults to 1 (no upscaling).\n",
    "        device (torch.device, optional): Device to perform computations on. Defaults to 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        float: Average PSNR value.\n",
    "    \"\"\"\n",
    "    total_psnr = 0.0\n",
    "    total_images = 0\n",
    "\n",
    "    # Get sorted lists of image filenames\n",
    "    pred_images = sorted(os.listdir(pred_folder))\n",
    "    target_images = sorted(os.listdir(target_folder))\n",
    "\n",
    "    # Ensure both folders have the same number of images\n",
    "    #if len(pred_images) != len(target_images):\n",
    "     #   raise ValueError(\"Prediction and target folders have different number of images.\")\n",
    "\n",
    "    for pred_img_name, target_img_name in tqdm(zip(pred_images, target_images), total=len(pred_images), desc=\"Calculating PSNR\"):\n",
    "        pred_path = os.path.join(pred_folder, pred_img_name)\n",
    "        target_path = os.path.join(target_folder, target_img_name)\n",
    "        print(f\"Processing: {pred_path} and {target_path}\")\n",
    "\n",
    "        # Open images and convert to RGB\n",
    "        pred_img = Image.open(pred_path).convert('RGB')\n",
    "        target_img = Image.open(target_path).convert('RGB')\n",
    "\n",
    "        # Convert images to tensors and normalize\n",
    "        pred_tensor = torch.from_numpy(np.array(pred_img)).float() / 255.0\n",
    "        target_tensor = torch.from_numpy(np.array(target_img)).float() / 255.0\n",
    "\n",
    "        # Ensure the dimensions are [C, H, W]\n",
    "        pred_tensor = pred_tensor.permute(2, 0, 1).to(device)\n",
    "        target_tensor = target_tensor.permute(2, 0, 1).to(device)\n",
    "\n",
    "        # Upscale the predicted image if upscale_factor > 1\n",
    "        if upscale_factor > 1:\n",
    "            # Add batch dimension: [1, C, H, W]\n",
    "            pred_tensor = pred_tensor.unsqueeze(0)\n",
    "\n",
    "            # Perform upscaling\n",
    "            pred_tensor = F.interpolate(pred_tensor, scale_factor=upscale_factor, mode='bicubic', align_corners=False)\n",
    "\n",
    "            # Remove batch dimension: [C, H, W]\n",
    "            pred_tensor = pred_tensor.squeeze(0)\n",
    "\n",
    "        # Compute PSNR\n",
    "        psnr_value = psnr(pred_tensor, target_tensor, max_val=1.0)\n",
    "        total_psnr += psnr_value\n",
    "        total_images += 1\n",
    "\n",
    "    # Compute average PSNR\n",
    "    avg_psnr = total_psnr / total_images\n",
    "    return avg_psnr\n",
    "\n",
    "# Define folder paths\n",
    "pred_folder_resShift = \"/home/vittorio/Documenti/Upsampling_CFD/results/test_DAT_x2_outdoor_no_umass/visualization/decoded\"\n",
    "pred_folder_bicubic_downsampled = '/home/vittorio/Scrivania/ETH/Upsampling/Upsampling_CFD/datasets/Split_Outdoor_Flow/test/low_res'\n",
    "target_folder_resShift = '/home/vittorio/Scrivania/ETH/Upsampling/ResShift_4_scale/data/Scalar_Images'\n",
    "# The target_folder_resShift is the same for bicubic as it's the high-resolution images\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Calculate PSNR for the model's output (ResShift)\n",
    "avg_psnr_resShift = calculate_psnr_from_folders(\n",
    "    pred_folder=pred_folder_resShift,\n",
    "    target_folder=target_folder_resShift,\n",
    "    upscale_factor=1,  # No upscaling needed for model outputs\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Calculate PSNR for Bicubic upscaled images\n",
    "# Since pred_folder_bicubic_downsampled contains downsampled images, we upscale them by a factor of 4\n",
    "avg_psnr_bicubic = calculate_psnr_from_folders(\n",
    "    pred_folder=pred_folder_bicubic_downsampled,\n",
    "    target_folder=target_folder_resShift,\n",
    "    upscale_factor=2,  # Upscale by a factor of 4\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"Validation PSNR - Model Output (ResShift): {avg_psnr_resShift:.2f} dB\")\n",
    "print(f\"Validation PSNR - Bicubic Upscaling: {avg_psnr_bicubic:.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating SSIM: 100%|██████████| 193/193 [00:01<00:00, 144.47it/s]\n",
      "Calculating SSIM: 100%|██████████| 193/193 [00:00<00:00, 254.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation SSIM - Model Output (ResShift): 0.9793\n",
      "Validation SSIM - Bicubic Upscaling: 0.8704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "\n",
    "def ssim(pred, target, C1=0.01**2, C2=0.03**2):\n",
    "    mu_x = F.conv2d(pred, weight=torch.ones([pred.shape[1], 1, 11, 11]).to(pred.device) / 121, padding=5, groups=pred.shape[1])\n",
    "    mu_y = F.conv2d(target, weight=torch.ones([target.shape[1], 1, 11, 11]).to(target.device) / 121, padding=5, groups=target.shape[1])\n",
    "\n",
    "    sigma_x = F.conv2d(pred * pred, weight=torch.ones([pred.shape[1], 1, 11, 11]).to(pred.device) / 121, padding=5, groups=pred.shape[1]) - mu_x ** 2\n",
    "    sigma_y = F.conv2d(target * target, weight=torch.ones([target.shape[1], 1, 11, 11]).to(target.device) / 121, padding=5, groups=target.shape[1]) - mu_y ** 2\n",
    "    sigma_xy = F.conv2d(pred * target, weight=torch.ones([pred.shape[1], 1, 11, 11]).to(pred.device) / 121, padding=5, groups=pred.shape[1]) - mu_x * mu_y\n",
    "\n",
    "    ssim_n = (2 * mu_x * mu_y + C1) * (2 * sigma_xy + C2)\n",
    "    ssim_d = (mu_x ** 2 + mu_y ** 2 + C1) * (sigma_x + sigma_y + C2)\n",
    "\n",
    "    ssim = ssim_n / ssim_d\n",
    "    return ssim.mean()\n",
    "\n",
    "def calculate_ssim_from_folders(pred_folder, target_folder, upscale_factor=1, device='cpu'):\n",
    "    \"\"\"\n",
    "    Calculate the average SSIM between images in two folders.\n",
    "\n",
    "    Args:\n",
    "        pred_folder (str): Path to the folder containing predicted/downsampled images.\n",
    "        target_folder (str): Path to the folder containing target high-resolution images.\n",
    "        upscale_factor (int, optional): Factor by which to upscale the predicted images.\n",
    "                                        Defaults to 1 (no upscaling).\n",
    "        device (torch.device, optional): Device to perform computations on. Defaults to 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        float: Average SSIM value.\n",
    "    \"\"\"\n",
    "    total_ssim = 0.0\n",
    "    total_images = 0\n",
    "\n",
    "    # Get sorted lists of image filenames\n",
    "    pred_images = sorted(os.listdir(pred_folder))\n",
    "    target_images = sorted(os.listdir(target_folder))\n",
    "\n",
    "    # Ensure both folders have the same number of images\n",
    "    if len(pred_images) != len(target_images):\n",
    "        raise ValueError(\"Prediction and target folders have different number of images.\")\n",
    "\n",
    "    for pred_img_name, target_img_name in tqdm(zip(pred_images, target_images), total=len(pred_images), desc=\"Calculating SSIM\"):\n",
    "        pred_path = os.path.join(pred_folder, pred_img_name)\n",
    "        target_path = os.path.join(target_folder, target_img_name)\n",
    "\n",
    "        # Open images and convert to RGB\n",
    "        pred_img = Image.open(pred_path).convert('RGB')\n",
    "        target_img = Image.open(target_path).convert('RGB')\n",
    "\n",
    "        # Convert images to tensors and normalize\n",
    "        pred_tensor = torch.from_numpy(np.array(pred_img)).float() / 255.0\n",
    "        target_tensor = torch.from_numpy(np.array(target_img)).float() / 255.0\n",
    "\n",
    "        # Ensure the dimensions are [C, H, W]\n",
    "        pred_tensor = pred_tensor.permute(2, 0, 1).to(device)  # Shape: [C, H, W]\n",
    "        target_tensor = target_tensor.permute(2, 0, 1).to(device)  # Shape: [C, H, W]\n",
    "\n",
    "        # Upscale the predicted image if upscale_factor > 1 using PyTorch's interpolate\n",
    "        if upscale_factor > 1:\n",
    "            # Add batch dimension: [1, C, H, W]\n",
    "            pred_tensor = pred_tensor.unsqueeze(0)\n",
    "\n",
    "            # Calculate new spatial dimensions based on upscale_factor\n",
    "            # Alternatively, you can use scale_factor=upscale_factor in interpolate\n",
    "            # but here we ensure it matches the target dimensions\n",
    "            target_height, target_width = target_tensor.shape[1], target_tensor.shape[2]\n",
    "            pred_tensor = F.interpolate(pred_tensor, size=(target_height, target_width), mode='bicubic', align_corners=False)\n",
    "\n",
    "            # Remove batch dimension: [C, H, W]\n",
    "            pred_tensor = pred_tensor.squeeze(0)\n",
    "\n",
    "        # Add batch dimension for SSIM function: [1, C, H, W]\n",
    "        pred_tensor = pred_tensor.unsqueeze(0)\n",
    "        target_tensor = target_tensor.unsqueeze(0)\n",
    "\n",
    "        # Compute SSIM\n",
    "        with torch.no_grad():\n",
    "            ssim_value = ssim(pred_tensor, target_tensor).item()\n",
    "        total_ssim += ssim_value\n",
    "        total_images += 1\n",
    "\n",
    "    # Compute average SSIM\n",
    "    avg_ssim = total_ssim / total_images\n",
    "    return avg_ssim\n",
    "\n",
    "# Define folder paths\n",
    "# Define folder paths\n",
    "pred_folder_resShift = \"/home/vittorio/Scrivania/ETH/Upsampling/Upsampling_CFD/results/swinir_classical_sr_x2\"\n",
    "pred_folder_bicubic_downsampled = '/home/vittorio/Scrivania/ETH/Upsampling/Upsampling_CFD/datasets/Split_Outdoor_Flow/test/low_res'\n",
    "target_folder_resShift = '/home/vittorio/Scrivania/ETH/Upsampling/Upsampling_CFD/datasets/Split_Outdoor_Flow/test/high_res'\n",
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Calculate SSIM for the model's output (ResShift)\n",
    "avg_ssim_resShift = calculate_ssim_from_folders(\n",
    "    pred_folder=pred_folder_resShift,\n",
    "    target_folder=target_folder_resShift,\n",
    "    upscale_factor=1,  # No upscaling needed for model outputs\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Calculate SSIM for Bicubic upscaled images\n",
    "avg_ssim_bicubic = calculate_ssim_from_folders(\n",
    "    pred_folder=pred_folder_bicubic_downsampled,\n",
    "    target_folder=target_folder_resShift,\n",
    "    upscale_factor=2,  # Upscale by a factor of 4\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\nValidation SSIM - Model Output (ResShift): {avg_ssim_resShift:.4f}\")\n",
    "print(f\"Validation SSIM - Bicubic Upscaling: {avg_ssim_bicubic:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Upsampling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
